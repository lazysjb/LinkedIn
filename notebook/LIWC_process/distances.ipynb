{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liwc_utils.distances import Euclidean, Cosine, Mahalanobis, JSDivergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIWC_NPZ_DIR = '/home/sjb/Projects/Research/LinkedIn_OB/data/word_features/company_level_liwc/raw_vectors/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_FILE = 'jpmorgan-chase_raw_liwc.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_liwc_data = np.load(os.path.join(LIWC_NPZ_DIR, SAMPLE_FILE), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_vectors = raw_liwc_data['person_vectors']\n",
    "company_vector = raw_liwc_data['company_vector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_euclidean_dist(array_of_vectors, compare_vector):\n",
    "    dist = np.linalg.norm(array_of_vectors - compare_vector, axis=1)\n",
    "    \n",
    "    return dist\n",
    "\n",
    "def calc_cosine_dist(array_of_vectors, compare_vector):\n",
    "    \"\"\"Define cosine distance as 1 - cosine similarity\"\"\"\n",
    "    cosine_sim_num = array_of_vectors.dot(compare_vector)\n",
    "    cosine_sim_denom = np.linalg.norm(array_of_vectors, axis=1) * np.linalg.norm(compare_vector)\n",
    "    cosine_similarity = cosine_sim_num / cosine_sim_denom\n",
    "    dist = 1 - cosine_similarity\n",
    "    \n",
    "    return dist\n",
    "    \n",
    "def calc_mahalanobis_dist(array_of_vectors, compare_vector):\n",
    "    V = np.cov(array_of_vectors, rowvar=False)\n",
    "    VI = np.linalg.inv(V)\n",
    "    \n",
    "    n = array_of_vectors.shape[0]\n",
    "    dist = np.zeros(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        dist[i] = mahalanobis(array_of_vectors[i], compare_vector, VI)\n",
    "        \n",
    "    return dist\n",
    "\n",
    "# https://stats.stackexchange.com/questions/7630/clustering-should-i-use-the-jensen-shannon-divergence-or-its-square\n",
    "def calc_js_divergence(array_of_vectors, compare_vector):\n",
    "    array_of_vectors_normalized = (array_of_vectors / array_of_vectors.sum(axis=1).reshape(-1, 1))\n",
    "    compare_vector_normalized = compare_vector / compare_vector.sum()\n",
    "    M = 0.5 * (array_of_vectors_normalized + compare_vector_normalized)\n",
    "    \n",
    "    n = array_of_vectors.shape[0]\n",
    "    dist = np.zeros(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        # base 2 is following the convention in \"Trajectories\" paper\n",
    "        kl_1 = entropy(array_of_vectors_normalized[i], M[i], base=2)\n",
    "        kl_2 = entropy(compare_vector_normalized, M[i], base=2)\n",
    "        dist[i] = 0.5 * (kl_1 + kl_2)\n",
    "        \n",
    "    return dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['company_person_ids', 'person_vectors', 'company_vector']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(raw_liwc_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_fns = [\n",
    "    calc_euclidean_dist,\n",
    "    calc_cosine_dist,\n",
    "    calc_mahalanobis_dist,\n",
    "    calc_js_divergence,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = []\n",
    "\n",
    "for dist_fn in dist_fns:\n",
    "    distances.append(dist_fn(person_vectors, company_vector).reshape(-1, 1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_1 = np.hstack(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_fns_2 = [\n",
    "    Euclidean,\n",
    "    Cosine,\n",
    "    Mahalanobis,\n",
    "    JSDivergence,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_new = []\n",
    "\n",
    "for dist_fn in dist_fns_2:\n",
    "    dist_metric = dist_fn(person_vectors, company_vector, standardize=False)\n",
    "    distances_new.append(dist_metric.calc_distance().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_2 = np.hstack(distances_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(distances_1 - distances_2).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = calc_js_divergence(person_vectors, company_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = entropy(person_vectors[0], company_vector, base=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator = person_vectors[0]+1e-4\n",
    "denom = company_vector + 1e-4\n",
    "\n",
    "numerator = numerator / numerator.sum()\n",
    "denom = denom / denom.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(numerator * np.log(numerator / denom) / np.log(2)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy(person_vectors[0], company_vector, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log((person_vectors[0]+1e-6) / (company_vector + 1e-6)) #/ np.log(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(person_vectors / person_vectors.sum(axis=1).reshape(-1, 1)).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(company_vector / company_vector.sum()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = calc_js_divergence(person_vectors, company_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = np.cov(np.array([array_1, array_2]).T)\n",
    "IV = np.linalg.inv(V)\n",
    "print(mahalanobis(array_1, array_2, IV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_distances = calc_euclidean_dist(person_vectors, company_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = np.cov(person_vectors, rowvar=False)\n",
    "IV = np.linalg.inv(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mahalanobis(person_vectors[0], company_vector, IV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = calc_mahalanobis_dist(person_vectors, company_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = calc_euclidean_dist(person_vectors, company_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = np.cov(\n",
    "    person_vectors, rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = person_vectors.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = person_vectors.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demeaned = person_vectors - mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov2 = (1 / (N - 1)) * (demeaned.T).dot(demeaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cov - cov2).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
